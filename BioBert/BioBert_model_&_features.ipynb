{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xqE5Ogz0sXRo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1748.1826651096344 seconds\n",
      "Model saved to biobert_model.pkl\n",
      "Model size: 433354997 bytes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      1104\n",
      "           1       0.87      0.87      0.87      1104\n",
      "\n",
      "    accuracy                           0.87      2208\n",
      "   macro avg       0.87      0.87      0.87      2208\n",
      "weighted avg       0.87      0.87      0.87      2208\n",
      "\n",
      "Accuracy: 0.8668478260869565\n",
      "MCC: 0.733696856125056\n",
      "AUC: 0.9354315991913463\n",
      "Sensitivity: 0.8677536231884058\n",
      "Specificity: 0.8659420289855072\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "# Read data from CSV files\n",
    "train_df = pd.read_csv('train_seq1.csv')  # Update with the correct file path\n",
    "test_df = pd.read_csv('test_seq.csv')    # Update with the correct file path\n",
    "\n",
    "# Extract sequences and labels from the dataframes\n",
    "train_sequences = train_df['sequence'].tolist()\n",
    "train_labels = train_df['label'].tolist()\n",
    "test_sequences = test_df['sequence'].tolist()\n",
    "test_labels = test_df['label'].tolist()\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "# Encode peptide sequences\n",
    "train_encodings = tokenizer(train_sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "test_encodings = tokenizer(test_sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Convert labels to tensors\n",
    "train_labels = torch.tensor(train_labels).long()\n",
    "test_labels = torch.tensor(test_labels).long()\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_inputs, test_inputs, train_masks, test_masks = train_encodings.input_ids, test_encodings.input_ids, \\\n",
    "                                                      train_encodings.attention_mask, test_encodings.attention_mask\n",
    "\n",
    "# Load pre-trained model\n",
    "model = BertForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", num_labels=2)\n",
    "\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "# Training loop\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "\n",
    "start_time = time.time()  # Start training time measurement\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(train_inputs), batch_size):\n",
    "        batch_inputs = train_inputs[i:i + batch_size]\n",
    "        batch_masks = train_masks[i:i + batch_size]\n",
    "        batch_labels = train_labels[i:i + batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs, attention_mask=batch_masks, labels=batch_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "end_time = time.time()  # End training time measurement\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training time: {training_time} seconds\")\n",
    "\n",
    "# Save the model to a .pkl file\n",
    "model_path = \"biobert_model.pkl\"\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Print the size of the model\n",
    "model_size = joblib.os.path.getsize(model_path)\n",
    "print(f\"Model size: {model_size} bytes\")\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_inputs, attention_mask=test_masks)\n",
    "    logits = outputs.logits\n",
    "    predictions = np.argmax(logits.cpu().numpy(), axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(test_labels, predictions))\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "mcc = matthews_corrcoef(test_labels, predictions)\n",
    "auc = roc_auc_score(test_labels, logits[:, 1])  # Assuming the second class is the positive class\n",
    "tn, fp, fn, tp = confusion_matrix(test_labels, predictions).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"MCC: {mcc}\")\n",
    "print(f\"AUC: {auc}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GIGSAILSAGKSIIKGLAKGLAEHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GCCSVPPCIANHPELCV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>GWCGDPGATCGKLRLYCCSGACDCYTKTCKDKSSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>GRCCHPACGQNTKC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>AFIEGSRGYFQRELKRTDLDLLEKFNFEAALAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8823</th>\n",
       "      <td>8823</td>\n",
       "      <td>0</td>\n",
       "      <td>IFCFLALVIAVASANKHGKNKDNAGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8824</th>\n",
       "      <td>8824</td>\n",
       "      <td>0</td>\n",
       "      <td>AIVEQQGAPGLGRIINKK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8825</th>\n",
       "      <td>8825</td>\n",
       "      <td>1</td>\n",
       "      <td>GCCSDPRCAWRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8826</th>\n",
       "      <td>8826</td>\n",
       "      <td>0</td>\n",
       "      <td>QADPNAFYGLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827</th>\n",
       "      <td>8827</td>\n",
       "      <td>1</td>\n",
       "      <td>CVKYLDPCDMLRHTCCFGLCVLIACI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8828 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  label                             sequence\n",
       "0              0      1            GIGSAILSAGKSIIKGLAKGLAEHF\n",
       "1              1      1                    GCCSVPPCIANHPELCV\n",
       "2              2      1  GWCGDPGATCGKLRLYCCSGACDCYTKTCKDKSSA\n",
       "3              3      1                       GRCCHPACGQNTKC\n",
       "4              4      0    AFIEGSRGYFQRELKRTDLDLLEKFNFEAALAT\n",
       "...          ...    ...                                  ...\n",
       "8823        8823      0           IFCFLALVIAVASANKHGKNKDNAGP\n",
       "8824        8824      0                   AIVEQQGAPGLGRIINKK\n",
       "8825        8825      1                         GCCSDPRCAWRC\n",
       "8826        8826      0                          QADPNAFYGLM\n",
       "8827        8827      1           CVKYLDPCDMLRHTCCFGLCVLIACI\n",
       "\n",
       "[8828 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_seq1.csv').iloc[:,0:20] \n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8828, 768)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pickle  # Import the pickle module\n",
    "\n",
    "# Read data from CSV files\n",
    "train_df = pd.read_csv('train_seq1.csv')#.iloc[0:20,:]  # Update with the correct file path\n",
    "\n",
    "# Extract sequences from the dataframe\n",
    "train_sequences = train_df['sequence'].tolist()\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "# Encode peptide sequences\n",
    "train_encodings = tokenizer(train_sequences, truncation=True, padding=True,max_length=35, return_tensors='pt')\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "# Forward pass to extract features (embeddings)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    outputs = model(**train_encodings)\n",
    "\n",
    "# Extract the features (embeddings) from the last hidden state\n",
    "features = outputs.last_hidden_state.numpy()\n",
    "\n",
    "# Save features to a .pkl file\n",
    "with open('Bio_bert_features.pkl', 'wb') as f:\n",
    "    pickle.dump(features, f)\n",
    "\n",
    "# embedding with mean pooling\n",
    "mean_pooled_features = np.mean(features, axis=1)\n",
    "mean_pooled_features.shape\n",
    "\n",
    "# 'features' now contains the embeddings for each token in your input sequences and is saved in 'features.pkl'\n",
    "# Save features to a .csv file\n",
    "c = pd.DataFrame(mean_pooled_features)\n",
    "print(c.shape)\n",
    "c.to_csv(\"Bio_bert_train_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n",
      "(2208, 768)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pickle  # Import the pickle module\n",
    "\n",
    "# Read data from CSV files\n",
    "train_df = pd.read_csv('test_seq.csv')#.iloc[0:20,:]  # Update with the correct file path\n",
    "\n",
    "# Extract sequences from the dataframe\n",
    "train_sequences = train_df['sequence'].tolist()\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "# Encode peptide sequences\n",
    "train_encodings = tokenizer(train_sequences, truncation=True, padding=True,max_length=35, return_tensors='pt')\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "print(model)\n",
    "# Forward pass to extract features (embeddings)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    outputs = model(**train_encodings)\n",
    "\n",
    "# Extract the features (embeddings) from the last hidden state\n",
    "features = outputs.last_hidden_state.numpy()\n",
    "\n",
    "# Save features to a .pkl file\n",
    "with open('Bio_bert_features.pkl', 'wb') as f:\n",
    "    pickle.dump(features, f)\n",
    "\n",
    "# embedding with mean pooling\n",
    "mean_pooled_features = np.mean(features, axis=1)\n",
    "mean_pooled_features.shape\n",
    "\n",
    "# 'features' now contains the embeddings for each token in your input sequences and is saved in 'features.pkl'\n",
    "# Save features to a .csv file\n",
    "c = pd.DataFrame(mean_pooled_features)\n",
    "print(c.shape)\n",
    "c.to_csv(\"Bio_bert_test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 19968)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m c \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(features),\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(c\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBio_bert_features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "c = features.reshape(len(features),-1)\n",
    "print(c.shape)\n",
    "df.to_csv(\"Bio_bert_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 19968)\n"
     ]
    }
   ],
   "source": [
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 768)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding with mean pooling\n",
    "mean_pooled_features = np.mean(features, axis=1)\n",
    "mean_pooled_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19958</th>\n",
       "      <th>19959</th>\n",
       "      <th>19960</th>\n",
       "      <th>19961</th>\n",
       "      <th>19962</th>\n",
       "      <th>19963</th>\n",
       "      <th>19964</th>\n",
       "      <th>19965</th>\n",
       "      <th>19966</th>\n",
       "      <th>19967</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295766</td>\n",
       "      <td>-0.248414</td>\n",
       "      <td>-0.174619</td>\n",
       "      <td>-0.081224</td>\n",
       "      <td>-0.133414</td>\n",
       "      <td>-0.332837</td>\n",
       "      <td>0.111752</td>\n",
       "      <td>0.159537</td>\n",
       "      <td>0.056456</td>\n",
       "      <td>0.287091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362634</td>\n",
       "      <td>0.244347</td>\n",
       "      <td>-0.566376</td>\n",
       "      <td>-0.710691</td>\n",
       "      <td>-0.103561</td>\n",
       "      <td>0.409266</td>\n",
       "      <td>-0.127931</td>\n",
       "      <td>0.433246</td>\n",
       "      <td>-0.031696</td>\n",
       "      <td>-0.583235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.555450</td>\n",
       "      <td>0.128328</td>\n",
       "      <td>-0.252557</td>\n",
       "      <td>-0.096326</td>\n",
       "      <td>-0.611277</td>\n",
       "      <td>-0.066753</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.283380</td>\n",
       "      <td>0.160758</td>\n",
       "      <td>0.077789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154250</td>\n",
       "      <td>0.206976</td>\n",
       "      <td>-0.330134</td>\n",
       "      <td>-0.342158</td>\n",
       "      <td>-0.475450</td>\n",
       "      <td>0.042247</td>\n",
       "      <td>-0.045918</td>\n",
       "      <td>0.418576</td>\n",
       "      <td>0.211306</td>\n",
       "      <td>0.123509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.471527</td>\n",
       "      <td>0.184619</td>\n",
       "      <td>-0.131111</td>\n",
       "      <td>0.104443</td>\n",
       "      <td>-0.116030</td>\n",
       "      <td>-0.482175</td>\n",
       "      <td>-0.096873</td>\n",
       "      <td>0.423787</td>\n",
       "      <td>-0.011152</td>\n",
       "      <td>-0.104417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712148</td>\n",
       "      <td>0.268008</td>\n",
       "      <td>-0.347479</td>\n",
       "      <td>-0.280486</td>\n",
       "      <td>-1.067829</td>\n",
       "      <td>0.532668</td>\n",
       "      <td>0.332722</td>\n",
       "      <td>-0.212920</td>\n",
       "      <td>-0.743492</td>\n",
       "      <td>-0.130254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.690550</td>\n",
       "      <td>0.066964</td>\n",
       "      <td>0.048544</td>\n",
       "      <td>0.053613</td>\n",
       "      <td>-0.196100</td>\n",
       "      <td>-0.478306</td>\n",
       "      <td>0.021435</td>\n",
       "      <td>0.455768</td>\n",
       "      <td>0.093702</td>\n",
       "      <td>0.064175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155600</td>\n",
       "      <td>0.082402</td>\n",
       "      <td>-0.308487</td>\n",
       "      <td>-0.667787</td>\n",
       "      <td>-0.216188</td>\n",
       "      <td>0.260508</td>\n",
       "      <td>-0.023848</td>\n",
       "      <td>0.149997</td>\n",
       "      <td>-0.018910</td>\n",
       "      <td>0.155258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.257410</td>\n",
       "      <td>-0.225721</td>\n",
       "      <td>0.288564</td>\n",
       "      <td>0.156947</td>\n",
       "      <td>-0.125648</td>\n",
       "      <td>-0.134172</td>\n",
       "      <td>-0.326167</td>\n",
       "      <td>0.118326</td>\n",
       "      <td>0.175957</td>\n",
       "      <td>-0.063314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.427944</td>\n",
       "      <td>0.303428</td>\n",
       "      <td>-0.338711</td>\n",
       "      <td>-0.757330</td>\n",
       "      <td>-0.185437</td>\n",
       "      <td>0.194008</td>\n",
       "      <td>0.093013</td>\n",
       "      <td>0.535545</td>\n",
       "      <td>-0.369737</td>\n",
       "      <td>-0.213575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.501313</td>\n",
       "      <td>-0.006330</td>\n",
       "      <td>0.025337</td>\n",
       "      <td>-0.101124</td>\n",
       "      <td>-0.215039</td>\n",
       "      <td>-0.479141</td>\n",
       "      <td>0.070616</td>\n",
       "      <td>0.252544</td>\n",
       "      <td>0.052038</td>\n",
       "      <td>0.059564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048654</td>\n",
       "      <td>-0.058742</td>\n",
       "      <td>-0.219182</td>\n",
       "      <td>-0.525096</td>\n",
       "      <td>-0.238855</td>\n",
       "      <td>0.171851</td>\n",
       "      <td>0.033156</td>\n",
       "      <td>0.259201</td>\n",
       "      <td>-0.128199</td>\n",
       "      <td>-0.008079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.436745</td>\n",
       "      <td>-0.093769</td>\n",
       "      <td>-0.019925</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>-0.237587</td>\n",
       "      <td>-0.422568</td>\n",
       "      <td>0.082617</td>\n",
       "      <td>0.449262</td>\n",
       "      <td>0.091441</td>\n",
       "      <td>0.154673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110469</td>\n",
       "      <td>0.087394</td>\n",
       "      <td>-0.332398</td>\n",
       "      <td>-0.798675</td>\n",
       "      <td>-0.092132</td>\n",
       "      <td>0.256308</td>\n",
       "      <td>0.144653</td>\n",
       "      <td>0.212850</td>\n",
       "      <td>-0.075593</td>\n",
       "      <td>-0.326994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.436316</td>\n",
       "      <td>-0.126130</td>\n",
       "      <td>-0.009946</td>\n",
       "      <td>-0.060373</td>\n",
       "      <td>-0.342109</td>\n",
       "      <td>-0.352349</td>\n",
       "      <td>0.086356</td>\n",
       "      <td>0.375431</td>\n",
       "      <td>0.111905</td>\n",
       "      <td>0.241896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171949</td>\n",
       "      <td>0.048242</td>\n",
       "      <td>-0.331375</td>\n",
       "      <td>-0.538188</td>\n",
       "      <td>-0.260457</td>\n",
       "      <td>0.454257</td>\n",
       "      <td>0.111089</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>-0.080075</td>\n",
       "      <td>0.171425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.355946</td>\n",
       "      <td>-0.234255</td>\n",
       "      <td>0.062280</td>\n",
       "      <td>0.060911</td>\n",
       "      <td>-0.167959</td>\n",
       "      <td>-0.455376</td>\n",
       "      <td>-0.095367</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.080931</td>\n",
       "      <td>0.135346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.338103</td>\n",
       "      <td>0.062188</td>\n",
       "      <td>-0.063671</td>\n",
       "      <td>-0.726631</td>\n",
       "      <td>-0.107139</td>\n",
       "      <td>0.629870</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>0.392437</td>\n",
       "      <td>-0.055412</td>\n",
       "      <td>-0.093124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.506715</td>\n",
       "      <td>0.199175</td>\n",
       "      <td>-0.091976</td>\n",
       "      <td>-0.013905</td>\n",
       "      <td>-0.361910</td>\n",
       "      <td>-0.187476</td>\n",
       "      <td>-0.039624</td>\n",
       "      <td>0.459731</td>\n",
       "      <td>0.167451</td>\n",
       "      <td>-0.067518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>-0.057924</td>\n",
       "      <td>-0.391357</td>\n",
       "      <td>-0.851090</td>\n",
       "      <td>-0.186147</td>\n",
       "      <td>0.102033</td>\n",
       "      <td>-0.081892</td>\n",
       "      <td>0.050635</td>\n",
       "      <td>-0.135018</td>\n",
       "      <td>-0.010355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 19968 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6      \\\n",
       "0  0.295766 -0.248414 -0.174619 -0.081224 -0.133414 -0.332837  0.111752   \n",
       "1  0.555450  0.128328 -0.252557 -0.096326 -0.611277 -0.066753  0.003202   \n",
       "2  0.471527  0.184619 -0.131111  0.104443 -0.116030 -0.482175 -0.096873   \n",
       "3  0.690550  0.066964  0.048544  0.053613 -0.196100 -0.478306  0.021435   \n",
       "4  0.257410 -0.225721  0.288564  0.156947 -0.125648 -0.134172 -0.326167   \n",
       "5  0.501313 -0.006330  0.025337 -0.101124 -0.215039 -0.479141  0.070616   \n",
       "6  0.436745 -0.093769 -0.019925  0.010236 -0.237587 -0.422568  0.082617   \n",
       "7  0.436316 -0.126130 -0.009946 -0.060373 -0.342109 -0.352349  0.086356   \n",
       "8  0.355946 -0.234255  0.062280  0.060911 -0.167959 -0.455376 -0.095367   \n",
       "9  0.506715  0.199175 -0.091976 -0.013905 -0.361910 -0.187476 -0.039624   \n",
       "\n",
       "      7         8         9      ...     19958     19959     19960     19961  \\\n",
       "0  0.159537  0.056456  0.287091  ... -0.362634  0.244347 -0.566376 -0.710691   \n",
       "1  0.283380  0.160758  0.077789  ...  0.154250  0.206976 -0.330134 -0.342158   \n",
       "2  0.423787 -0.011152 -0.104417  ...  0.712148  0.268008 -0.347479 -0.280486   \n",
       "3  0.455768  0.093702  0.064175  ...  0.155600  0.082402 -0.308487 -0.667787   \n",
       "4  0.118326  0.175957 -0.063314  ... -0.427944  0.303428 -0.338711 -0.757330   \n",
       "5  0.252544  0.052038  0.059564  ...  0.048654 -0.058742 -0.219182 -0.525096   \n",
       "6  0.449262  0.091441  0.154673  ...  0.110469  0.087394 -0.332398 -0.798675   \n",
       "7  0.375431  0.111905  0.241896  ... -0.171949  0.048242 -0.331375 -0.538188   \n",
       "8  0.019830  0.080931  0.135346  ... -0.338103  0.062188 -0.063671 -0.726631   \n",
       "9  0.459731  0.167451 -0.067518  ...  0.000247 -0.057924 -0.391357 -0.851090   \n",
       "\n",
       "      19962     19963     19964     19965     19966     19967  \n",
       "0 -0.103561  0.409266 -0.127931  0.433246 -0.031696 -0.583235  \n",
       "1 -0.475450  0.042247 -0.045918  0.418576  0.211306  0.123509  \n",
       "2 -1.067829  0.532668  0.332722 -0.212920 -0.743492 -0.130254  \n",
       "3 -0.216188  0.260508 -0.023848  0.149997 -0.018910  0.155258  \n",
       "4 -0.185437  0.194008  0.093013  0.535545 -0.369737 -0.213575  \n",
       "5 -0.238855  0.171851  0.033156  0.259201 -0.128199 -0.008079  \n",
       "6 -0.092132  0.256308  0.144653  0.212850 -0.075593 -0.326994  \n",
       "7 -0.260457  0.454257  0.111089  0.134799 -0.080075  0.171425  \n",
       "8 -0.107139  0.629870  0.134321  0.392437 -0.055412 -0.093124  \n",
       "9 -0.186147  0.102033 -0.081892  0.050635 -0.135018 -0.010355  \n",
       "\n",
       "[10 rows x 19968 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"Bio_bert_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15abdb5fc76a409e8c18ae556875df35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a5d9dd071984a43a45b7cd0ee6e49a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e607adc51db4011b37bee1417fbc407": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6479640d8ed94dcea573e3a9dd8eed86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f31ffffbaf84344a1825c2d683d5cc3",
      "placeholder": "​",
      "style": "IPY_MODEL_3a5d9dd071984a43a45b7cd0ee6e49a9",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "7f31ffffbaf84344a1825c2d683d5cc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "843312e9ac34492e9ef52a08debb1b96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92414e2a7e9a4d16a8c7a688050d766d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ed54296151f4b339ec868287c1277e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6479640d8ed94dcea573e3a9dd8eed86",
       "IPY_MODEL_e9e90ada10c6469aba3d3e9ac481dc84",
       "IPY_MODEL_e0ba52ef64c444908d6ab79ef1ab0a77"
      ],
      "layout": "IPY_MODEL_4e607adc51db4011b37bee1417fbc407"
     }
    },
    "e0ba52ef64c444908d6ab79ef1ab0a77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_843312e9ac34492e9ef52a08debb1b96",
      "placeholder": "​",
      "style": "IPY_MODEL_fbf4ad060d1e47e08b71fa72a2086fa1",
      "value": " 436M/436M [00:05&lt;00:00, 123MB/s]"
     }
    },
    "e9e90ada10c6469aba3d3e9ac481dc84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92414e2a7e9a4d16a8c7a688050d766d",
      "max": 435780550,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_15abdb5fc76a409e8c18ae556875df35",
      "value": 435780550
     }
    },
    "fbf4ad060d1e47e08b71fa72a2086fa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
